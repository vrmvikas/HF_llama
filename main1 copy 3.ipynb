{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7b415405ed437988043ccc186c0e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9,\n",
      "  \"transformers_version\": \"4.33.2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    return_dict=True,\n",
    "    # load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "print(generation_config)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str, max_new_tokens: int = 128, temperature: float = 0.001) -> str:\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **encoding,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.001,\n",
    "            generation_config=generation_config,\n",
    "\n",
    "            do_sample = True,\n",
    "        )\n",
    "    answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "    return tokenizer.decode(answer_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# def format_prompt(prompt, history='', Background=''):\n",
    "#     return f\"\"\"<s>[INST] <<SYS>>\n",
    "# {{ \n",
    "#     {Background}\n",
    "#     {history}\n",
    "# }}\n",
    "# <</SYS>>\n",
    "# [/INST]  </s><s>[INST]  [/INST]  </s><s>[INST]  [/INST]  </s><s>[INST] {{ {prompt} }} [/INST]\"\"\"\n",
    "\n",
    "def format_prompt(prompt, history='', Background=''):\n",
    "    return f\"\"\"<s>[INST] <<SYS>>\n",
    "{{ \n",
    "    {Background}\n",
    "    {history}\n",
    "}}\n",
    "<</SYS>>\n",
    "[/INST]  </s>\n",
    "<s>[INST] {{ {prompt} }} [/INST]\"\"\"\n",
    "\n",
    "\n",
    "# def format_prompt(prompt, history='', Background=''):\n",
    "#     return f\"\"\"\n",
    "#     {Background}\n",
    "#     {history}\n",
    "#     {prompt}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3329911007.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 40\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "The_Topic = '\"ways to detect if a news is fake or real\"'\n",
    "User_A = \"Tom\"\n",
    "User_B = \"Jerry\"\n",
    " \n",
    "Background_for_A = f'You are {User_A}. The topic of the discussion id {The_Topic}. Ask a question or write a response that answers the question of {User_B} according to the conversation history, or with a new information. Answer in one short sentence only and strictly, do not repeat what is already said in the conversation. If you have nothing new to add, reply with a thanks.'\n",
    "Background_for_B = f'You are {User_B}. The topic of the discussion id {The_Topic}. Ask a question or write a response that answers the question of {User_A} according to the conversation history, or with a new information. Answer in one short sentence only and strictly, do not repeat what is already said in the conversation. If you have nothing new to add, reply with a thanks.'\n",
    "Background = ''\n",
    "the_output = ''\n",
    "\n",
    "history = f'''\n",
    "{User_A}: Hello, I am {User_A}\n",
    "{User_B}:  Hello {User_A}, I am {User_B}\n",
    "'''\n",
    "prompt_to_A = f\"Hello {User_A}, I am {User_B}\"\n",
    "\n",
    "for j in trange(1,30):\n",
    "    try:\n",
    "        prompt_to_B = generate_response(format_prompt(prompt_to_A, history, Background_for_A), 150, 0.001)\n",
    "        if prompt_to_B[:len(User_A)] == User_A:\n",
    "            history += prompt_to_B + '\\n'\n",
    "        else:\n",
    "            history += f\"{User_A}: \" + prompt_to_B + '\\n'\n",
    "\n",
    "        prompt_to_A = generate_response(format_prompt(prompt_to_B, history, Background_for_B), 150, 0.001)\n",
    "        if prompt_to_A[:len(User_B)] == User_B:\n",
    "            history += prompt_to_A + '\\n'\n",
    "        else:\n",
    "            history += f\"{User_B}: \" + prompt_to_A + '\\n'\n",
    "        \n",
    "        if not j % 5:\n",
    "            summary = generate_response(format_prompt(\"What are the keypoints of above chat and summary, in very very short.\", history), 500)\n",
    "            summary = '\\n'.join(summary.strip().split('\\n')[1:])\n",
    "            history = \"We know that\\n\" + summary +'\\n' + f'''\n",
    "{User_A}: Hello, I am {User_A}\n",
    "{User_B}:  Hello {User_A}, I am {User_B}\n",
    "'''\n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We know that\n",
      "* Common signs of a fake news article include lack of credible sources, sensationalized headlines, and emotional appeals.\n",
      "* Clickbait headlines and overly simplistic or sensationalized language can also indicate a fake news article.\n",
      "* Unverifiable or unreliable sources, such as anonymous sources or sources with a clear bias or agenda, can be a sign of a fake news article.\n",
      "* Manipulated or altered images, videos, or other media can be easily debunked with a simple fact-check.\n",
      "* It's important to fact-check visual evidence presented in an article to ensure its authenticity.\n",
      "* Being vigilant and skeptical when consuming news is crucial in today's digital age where misinformation can spread quickly.\n",
      "\n",
      "Tom: Hello, I am Tom\n",
      "Jerry:  Hello Tom, I am Jerry\n",
      " Thanks, Jerry! That's a great point. It's important to fact-check not only the text of a news article but also any visual evidence or images included in it. This can help us identify manipulated or altered images that may be used to deceive readers. By being vigilant and skeptical, we can better protect ourselves from misinformation and make informed decisions.\n",
      " Jerry: Absolutely, Tom! It's crucial to be aware of any inconsistencies or red flags in the visual content of a news article, such as blurry or low-quality images, or images that have been manipulated to misrepresent the facts. By carefully examining the visual evidence presented in a news article, we can gain a more complete understanding of the story and make more informed decisions.\n",
      " Tom: That's a great point, Jerry. It's important to also consider the context in which the visual evidence is presented. For example, if an image is taken out of context or used to support a claim that it was not intended to make, it can be misleading. By carefully evaluating the context in which visual evidence is presented, we can better determine its accuracy and reliability.\n",
      " Jerry: Ah, I see. Yes, the context in which visual evidence is presented can be just as important as the visual evidence itself. It's easy for manipulators to take an image out of context and use it to support a false claim, so it's crucial to consider the broader context in which the image is being used. For example, if an image is taken from a different time or place than the article claims, it can be a clear sign of manipulation. By carefully evaluating the context, we can better determine the accuracy and reliability of the visual evidence.\n",
      " Tom: That's a great point, Jerry. It's important to consider the source of the visual evidence as well. If the image or video is from an unverifiable or unreliable source, it may be more likely to be manipulated or misleading. By evaluating the source of the visual evidence and considering its credibility, we can make more informed decisions about its accuracy and reliability.\n",
      " Jerry: Absolutely, Tom. The source of the visual evidence is crucial in determining its accuracy and reliability. Unverifiable or unreliable sources can often be manipulated or biased, which can lead to misinformation. By evaluating the source of the visual evidence and considering its credibility, we can make more informed decisions about the validity of the information it presents.\n",
      " Tom: That's a great point, Jerry. It's important to consider the credibility of the source of the visual evidence, as unverifiable or unreliable sources can often be manipulated or biased. By evaluating the source of the visual evidence and considering its credibility, we can make more informed decisions about the validity of the information it presents.\n",
      " Jerry: Absolutely, Tom. And it's not just the source of the visual evidence that's important, but also the context in which it's presented. For example, if an image is taken out of context or used to support a claim that it was not intended to make, it can be misleading. By carefully evaluating the context in which visual evidence is presented, we can better determine its accuracy and reliability.\n",
      " Tom: That's a great point, Jerry. The context in which visual evidence is presented can greatly impact its accuracy and reliability. It's important to consider the broader context in which the image or video is being used, including the claims being made and the intentions of the person or organization presenting it. By carefully evaluating the context, we can better determine whether the visual evidence is being used to deceive or mislead.\n",
      " Jerry: Absolutely, Tom. The context in which visual evidence is presented is crucial in determining its accuracy and reliability. It's important to consider the broader context, including the claims being made and the intentions of the person or organization presenting the image or video. By carefully evaluating the context, we can better identify any potential biases or manipulations and make more informed decisions about the validity of the visual evidence.\n",
      " Tom: Great point, Jerry. It's important to consider the intentions of the person or organization presenting the visual evidence, as they can often influence the way the evidence is presented and interpreted. By evaluating the intentions behind the presentation of the visual evidence, we can better determine its accuracy and reliability.\n",
      " Jerry: Absolutely, Tom. The intentions of the person or organization presenting the visual evidence can indeed impact the way it is interpreted and evaluated. For example, if the intent is to deceive or manipulate, the visual evidence may be presented in a way that is misleading or false. By carefully considering the intentions behind the presentation of the visual evidence, we can better identify any potential biases or manipulations and make more informed decisions about its accuracy and reliability.\n",
      " Tom: That's a great point, Jerry. The intentions of the person or organization presenting the visual evidence can indeed impact how it is interpreted and evaluated. By considering the intentions behind the presentation of the visual evidence, we can better identify any potential biases or manipulations and make more informed decisions about its accuracy and reliability. Thanks for pointing this out!\n",
      " Jerry: Of course, Tom! It's crucial to consider the intentions of the person or organization presenting the visual evidence, as they can often influence how the evidence is presented and interpreted. By evaluating the intentions behind the presentation, we can better identify any potential biases or manipulations and make more informed decisions about the accuracy and reliability of the visual evidence. Thanks for highlighting this important factor!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here are the key points of the chat in very short summary:\n",
      "* Common signs of a fake news article include lack of credible sources, sensationalized headlines, and emotional appeals.\n",
      "* Fake news articles often use clickbait headlines, overly simplistic or sensationalized language, and unverifiable sources.\n",
      "* Lack of fact-checking or evidence to support claims is also a red flag.\n",
      "* Manipulated or altered images or videos can be used to support false claims.\n",
      "* Emotional appeals and loaded language can be used to manipulate the reader's emotions rather than presenting balanced and factual information.\n"
     ]
    }
   ],
   "source": [
    "summary = generate_response(format_prompt(\"What are the keypoints of above chat and summary, in very very short.\", history), 500)\n",
    "newsummary = '\\n'.join(summary.strip().split('\\n')[1:])\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6608\n",
      "704\n"
     ]
    }
   ],
   "source": [
    "# newsummary = '\\n'.join(summary.strip().split('\\n')[1:])\n",
    "# print(newsummary)\n",
    "print(len(history))\n",
    "print(len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/suraj/vrmvikas/LLaMA/HF_llama/main1.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.34.32/home/suraj/vrmvikas/LLaMA/HF_llama/main1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     file\u001b[39m.\u001b[39mwrite(history)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.34.32/home/suraj/vrmvikas/LLaMA/HF_llama/main1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     file\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39mSummary\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.34.32/home/suraj/vrmvikas/LLaMA/HF_llama/main1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     file\u001b[39m.\u001b[39mwrite(summary)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.34.32/home/suraj/vrmvikas/LLaMA/HF_llama/main1.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Close the file when you're done (the 'with' statement automatically does this)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the string you want to append to the file\n",
    "text_to_append = \"This is additional text to append to the file.\"\n",
    "\n",
    "# Specify the file path where you want to append the text\n",
    "file_path = f\"./{The_Topic}.txt\"\n",
    "file_path = f\"./AGI_tobeinvented.txt\"\n",
    "\n",
    "# Open the file in append mode ('a' for appending)\n",
    "with open(file_path, 'a') as file:\n",
    "    # Write the string to the file\n",
    "    file.write(\"Conversation\\n\\n\")\n",
    "    file.write(history)\n",
    "    file.write(\"Summary\\n\\n\")\n",
    "    file.write(summary)\n",
    "\n",
    "# Close the file when you're done (the 'with' statement automatically does this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_for_A = '''\n",
    "# User A: Hello, I am User A. \n",
    "# User B:  Hello User A, I am User B.\n",
    "# '''\n",
    "\n",
    "# history_for_B = '''\n",
    "# User A: Hello, I am User A.\n",
    "# User B: Hello User A, I am User B.\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed_Prefix = \"Write a response that answers the request according to the conversation history below. Answer in one short sentence only.\"\n",
    "# Background_for_A = 'Talk about Fake news with User B'\n",
    "# Background_for_B = 'Talk about Fake news with User A'\n",
    "# Background = ''\n",
    "# the_output = ''\n",
    "# Fixed_Prefix_len = len(Fixed_Prefix)\n",
    "# import sys\n",
    "# history = '''\n",
    "# User A: Hello, I am User A.\n",
    "# User B:  Hello!\n",
    "# '''\n",
    "# for j in range(1,50):\n",
    "#     if not j % 5:    \n",
    "#         summary = generate_response(format_prompt(\"What are the keypoints of above chat and summary, in very very short.\", history), 500)\n",
    "#         Background += '\\n' + ''.join(Background.strip().split('\\n')[1:])\n",
    "#         history = '\\n'\n",
    "#     print(Background)\n",
    "#     # print(history)\n",
    "#     print(the_output)\n",
    "#     print(j, \"*\" * 50)\n",
    "#     while True:\n",
    "#         prompt = input()\n",
    "#         if len(prompt) == 0:\n",
    "#             continue\n",
    "#         else:\n",
    "#             break\n",
    "#     if prompt == 'quit':\n",
    "#         break\n",
    "#     the_output = generate_response(format_prompt(prompt, history), 200, 0.001)\n",
    "#     history += \"Request: \" + prompt + '\\n'\n",
    "#     history += \"Response: \" + the_output + '\\n\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lams",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
