{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/anaconda3/envs/lams/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    # local_files_only=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    # device_map=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_string = \"Who is..\"\n",
    "for ii in range(10):\n",
    "    sequences = pipeline(\n",
    "        ip_string,\n",
    "\n",
    "        do_sample=True,\n",
    "        # do_sample=False,\n",
    "        \n",
    "        \n",
    "        # top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=200,\n",
    "    )\n",
    "    for seq in sequences:\n",
    "        print(f\"{ii}  Result: {seq['generated_text']}\")\n",
    "        ip_string = seq['generated_text'].split('\\n')[1]\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_string=seq['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence. \n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence. \n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence. \n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence. \n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n",
      "Identifying Fake News is a big problem that we are facing today. What is your opinion regarding this? Do not generate code. Reply in a short sentence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \" What is your opinion regarding this? Do not generate code. Reply in a short sentence.\"\n",
    "ip_string='Identifying Fake News is a big problem that we are facing today.'\n",
    "for _ in range(50):\n",
    "    sequences = pipeline(\n",
    "        ip_string + commands,\n",
    "\n",
    "        do_sample=True,\n",
    "        # do_sample=False,\n",
    "        \n",
    "        \n",
    "        # top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=30,\n",
    "    )\n",
    "    for seq in sequences:\n",
    "        # print(f\"{ii}  Result:\\n{seq['generated_text']}\\n\\n\")\n",
    "        try:\n",
    "            print(seq['generated_text'])\n",
    "            # print(seq['generated_text'].split('.')[1])\n",
    "            # ip_string = seq['generated_text'].split('.')[1]\n",
    "\n",
    "        except:\n",
    "            print(seq['generated_text'])\n",
    "            # ip_string = seq['generated_text'][len(ip_string):]\n",
    "        # print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/anaconda3/envs/lams/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying Fake News is a big problem that we are facing today. Here are some of the reasons why it is important to identify fake news:\n",
      "1. Protecting Democracy: Fake news can be used to manipulate public opinion and undermine democratic institutions. By identifying and correcting fake news, we can protect democracy and ensure that citizens have access to accurate information.\n",
      "2. Preventing Social Unrest: Fake news can also be used to\n",
      " Here are some of the reasons why it is important to identify fake news:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "ip_string=\"Identifying Fake News is a big problem that we are facing today.\"\n",
    "sequences = pipeline(\n",
    "    ip_string,\n",
    "\n",
    "    do_sample=True,\n",
    "    # do_sample=False,\n",
    "    \n",
    "    \n",
    "    # top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=max(len(ip_string),100),\n",
    ")\n",
    "for seq in sequences:\n",
    "    # print(f\"{ii}  Result:\\n{seq['generated_text']}\\n\\n\")\n",
    "    # try:\n",
    "        # print(seq['generated_text'].split('.')[1])\n",
    "    # except:\n",
    "    print(seq['generated_text'])\n",
    "    print(seq['generated_text'].split('.')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out <<< Yes, you can definitely talk in Hindi on this platform! ðŸ™Œ\n",
      "\n",
      "à¤¹à¤¾à¤, à¤†à¤ªà¤•à¥‹ à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤¬à¤¾à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "commands = \" What is your opinion regarding this? Do not generate code. Reply in a short sentence.\"\n",
    "commands = \" Give your opinions in short.\"\n",
    "commands = \"\"\n",
    "ip_string='Identifying Fake News is a big problem that we are facing today.'\n",
    "ip_string = '''[INST] <<<.SYS>>>\n",
    "<<<./SYS>>>\n",
    "\n",
    "Hindi mein baat kar sakte ho?[/INST]'''\n",
    "# ip_string = \"Write a poem to help me remember the first 10 elements on the periodic table, giving each element its own line.\"\n",
    "no_of_outputs = 0\n",
    "errorCounts = 0\n",
    "printStats = False\n",
    "errorState = False\n",
    "# print(\"First In  >>> \" + ip_string)\n",
    "while no_of_outputs < 1 and errorCounts < 200:\n",
    "    # if not errorState:\n",
    "        # print(\"In  >>> \" + ip_string)\n",
    "    sequences = pipeline(\n",
    "        ip_string + commands,\n",
    "\n",
    "        do_sample=True,\n",
    "        # do_sample=False,\n",
    "        \n",
    "        \n",
    "        # top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=500,\n",
    "    )\n",
    "    for seq in sequences:\n",
    "        rawoutput = seq['generated_text']\n",
    "        a = len(ip_string + commands)\n",
    "        b = len(seq['generated_text'])\n",
    "        the_difference = b-a\n",
    "        if rawoutput[:a] == ip_string + commands:\n",
    "            output = rawoutput[a:].strip()\n",
    "        if the_difference < 10:\n",
    "            if printStats:    \n",
    "                print(\">>Less Difference\")\n",
    "            errorCounts += 1\n",
    "            errorState = True\n",
    "\n",
    "            continue\n",
    "        else:\n",
    "            ip_string = output    \n",
    "            no_of_outputs += 1\n",
    "\n",
    "\n",
    "        # print(\"RawOutput <<< \", rawoutput)\n",
    "        print(\"Out <<< \" + output)\n",
    "        errorState = False\n",
    "        if printStats:\n",
    "            print(\"Input Length\", a)\n",
    "            print(\"Output Length\", b)\n",
    "            print(\"Difference \", the_difference )\n",
    "            # print(output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a poem to help me remember the first 10 elements on the periodic table, giving each element its own line.\n",
      "\n",
      "Answer: Sure, here's a poem to help you remember the first 10 elements on the periodic table:\n",
      "\n",
      "Hydrogen, the first one on the list,\n",
      "Light as a feather, yet so quite blessed.\n",
      "Helium, the second, so rare and light,\n",
      "Gas that floats, and makes our voices bright.\n",
      "Lithium, the third, so reactive and bold,\n",
      "Burns with fire, and makes our hearts unfold.\n",
      "Beryllium, the fourth, so strong and sturdy,\n",
      "Metal that shines, and makes our spirits steady.\n",
      "Boron, the fifth, so small but mighty,\n",
      "Keeps our homes safe, and makes our lives more steady.\n",
      "Carbon, the sixth, so versatile and grand,\n"
     ]
    }
   ],
   "source": [
    "print(rawoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lams",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
