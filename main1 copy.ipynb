{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/anaconda3/envs/lams/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [10:13<00:00, 306.61s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    return_dict=True,\n",
    "    # load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"do_sample\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 4096,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"temperature\": 0.6,\n",
       "  \"top_p\": 0.9,\n",
       "  \"transformers_version\": \"4.33.2\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My name is Vikas\"\n",
    "# prompt = \"Names of my friends are: Anmol, Aryan, Joel. How many friends do I have?\"\n",
    "prompt = \"Do you recall the names of my three friends?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,  1938,   366, 17386,   278,  2983,   310,   590,  2211,  7875,\n",
      "         29973]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "tensor([[    1,  1938,   366, 17386,   278,  2983,   310,   590,  2211,  7875,\n",
      "         29973]], device='cuda:0')\n",
      "torch.Size([1, 11])\n"
     ]
    }
   ],
   "source": [
    "print(encoding)\n",
    "print(encoding.input_ids)\n",
    "print(encoding.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **encoding,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.0001,\n",
    "        generation_config=generation_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 1\n",
      "shape torch.Size([1, 54])\n"
     ]
    }
   ],
   "source": [
    "print(\"len\", len(outputs))\n",
    "print(\"shape\", outputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you recall the names of my three friends?\n",
      "\n",
      "I'm glad you asked! They are John, Sarah, and... (pauses and looks at you with a mischievous grin) ...Moo! (winks)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape torch.Size([1, 214])\n",
      "Inpute Shape torch.Size([1, 10])\n",
      "New shape torch.Size([1, 204])\n",
      "?\n",
      "\n",
      "Vikas is a digital marketing expert and a social media influencer. He is the founder of @vrmvikas, a digital marketing agency that helps businesses grow their online presence through social media marketing, SEO, content marketing, and more.\n",
      "Vikas is also a popular social media influencer with over 100k followers on Instagram. He shares tips and insights on digital marketing, social media marketing, and entrepreneurship through his posts and stories.\n",
      "In addition to his work as a digital marketing agency owner and social media influencer, Vikas is also a sought-after speaker and trainer. He has delivered talks and workshops on digital marketing and social media marketing at various events and conferences.\n",
      "Overall, Vikas is a highly respected figure in the digital marketing industry, known for his expertise and passion for helping businesses succeed online.\n"
     ]
    }
   ],
   "source": [
    "answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "\n",
    "\n",
    "print(\"Original shape\", outputs.shape)\n",
    "print(\"Inpute Shape\", encoding.input_ids.shape)\n",
    "print(\"New shape\", answer_tokens.shape)\n",
    "\n",
    "\n",
    "\n",
    "output_text = tokenizer.decode(answer_tokens[0], skip_special_tokens=True).strip()\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(prompt: str, system_prompt: str) -> str:\n",
    "    return f\"\"\"\n",
    "{system_prompt}\n",
    "{prompt}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str, max_new_tokens: int = 128) -> str:\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **encoding,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.001,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "    answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "    return tokenizer.decode(answer_tokens[0], skip_special_tokens=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Write an email to a director flaunting about your movie career\n",
    "\"\"\".strip()\n",
    "response = generate_response(format_prompt(prompt, SYSTEM_PROMPT), max_new_tokens=512)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vikas Verm'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_prompt(prompt, SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and achievements.\n",
      "Subject: My illustrious career in cinema\n",
      "Dear [Director's Name],\n",
      "I hope this email finds you in the best of spirits. As a fellow filmmaker, I am writing to share with you my immense pride and satisfaction in the illustrious career that I have had the privilege of pursuing in the world of cinema.\n",
      "Over the years, I have had the good fortune of being a part of some of the most iconic and memorable films in Indian cinema. From my debut in the 1970s to the present day, I have consistently delivered performances that have left audiences in awe and inspired generations of actors to follow in my footsteps.\n",
      "My filmography boasts of a diverse range of roles, from the intense and brooding anti-hero in \"Deewar\" to the charismatic and larger-than-life figure in \"Sholay\". I have essayed complex and nuanced characters with ease, bringing to life some of the most memorable characters in Indian cinema. My performances have been widely acclaimed and have earned me numerous awards and accolades, including several National Film Awards and Filmfare Awards.\n",
      "But my impact on Indian cinema extends beyond my performances on screen. As a producer and entrepreneur, I have been instrumental in shaping the industry and creating opportunities for new talent to emerge. My production house, Amitabh Bachchan Corporation Limited, has produced several successful films and has played a significant role in the growth of the industry.\n",
      "In short, my career in cinema has been a journey of passion, dedication, and hard work. I am proud of the legacy that I have created and the impact that I have had on Indian cinema. I hope that my story will continue to inspire and motivate future generations of filmmakers to follow their dreams and make their mark on the industry.\n",
      "Thank you for taking the time to read about my career. I look forward to continuing to make great films and entertaining audiences for years to come.\n",
      "Best regards,\n",
      "Amitabh Bachchan\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Fake News is becoming a huge problem today.\n",
    "\"\"\".strip()\n",
    "responses = []\n",
    "for _ in range(10):\n",
    "    response = generate_response(format_prompt(prompt, SYSTEM_PROMPT), max_new_tokens=200)\n",
    "    print(response)\n",
    "    SYSTEM_PROMPT = \"You know that \" + response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Write a response that answers the request according to the conversation history below.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lams",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
